between = c(block_order, rule),
type = 3,
x = trial_type,
split = rule)
ezPlot(data = data,
dv = D_score,
wid = participant,
within = trial_type,
between = c(block_order, rule),
type = 3,
x = trial_type,
split = c(rule, block_order))
ezPlot(data = data,
dv = D_score,
wid = participant,
within = trial_type,
between = c(block_order, rule),
type = 3,
x = trial_type,
split = interaction(rule, block_order))
ezPlot(data = data,
dv = D_score,
wid = participant,
within = trial_type,
between = c(block_order, rule),
type = 3,
x = trial_type,
split = rule)
ezPlot(data = data,
dv = D_score,
wid = participant,
within = trial_type,
between = c(block_order, rule),
type = 3,
x = trial_type,
split = rule,
do_lines = FALSE)
ezPlot(data = data,
dv = D_score,
wid = participant,
within = trial_type,
between = c(block_order, rule),
type = 3,
x = trial_type,
split = rule,
do_lines = FALSE,
print_code = TRUE)
x <- ezPlot(data = data,
dv = D_score,
wid = participant,
within = trial_type,
between = c(block_order, rule),
type = 3,
x = trial_type,
split = rule,
do_lines = FALSE,
print_code = TRUE)
x <- ezPlot(data = data,
dv = D_score,
wid = participant,
within = trial_type,
between = c(block_order, rule),
type = 3,
x = trial_type,
split = rule,
do_lines = FALSE,
print_code = TRUE)
x <- ezPlot(data = data,
dv = D_score,
wid = participant,
within = trial_type,
between = c(block_order, rule),
type = 3,
x = trial_type,
split = rule,
do_lines = FALSE)
x <- ezPlot(data = data,
dv = D_score,
wid = participant,
within = trial_type,
#between = c(block_order, rule),
type = 3,
x = trial_type,
split = rule,
do_lines = FALSE)
x <- ezPlot(data = data,
dv = D_score,
wid = participant,
within = trial_type,
between = NULL,
type = 3,
x = trial_type,
split = rule,
do_lines = FALSE)
x <- ezPlot(data = data,
dv = D_score,
wid = participant,
within = trial_type,
between = NULL,
type = 3,
x = trial_type,
do_lines = FALSE)
ezPlot(data = data,
dv = D_score,
wid = participant,
within = trial_type,
between = NULL,
type = 3,
x = trial_type,
do_lines = FALSE)
fit_selected_2$`--- FORMATTED RESULTS ------------------------------------`
fit_selected_2 <-
ez::ezANOVA(data = data,
dv = D_score,
within = trial_type,
between = c(block_order, rule),
wid = participant,
type = 3,
detailed = TRUE) %>%
schoRsch::anova_out(print = FALSE)
fit_selected_2$`--- FORMATTED RESULTS ------------------------------------`
summary_data <- data %>%
group_by(trial_type, rule, block_order) %>%
summarize(mean_D_score = round(mean(D_score), 2))
ggplot(summary_data) +
geom_point(aes(x = trial_type, y = mean_D_score, colour = interaction(rule, block_order)),
position = position_jitterdodge(dodge.width = .5))
# http://www.cookbook-r.com/Statistical_analysis/ANOVA/
# forward selection
# variable 1
# null model
fit_0 <- aov(D_score ~ Error(participant/trial_type),
data = data)
# tt
fit_1a <- aov(D_score ~ trial_type + Error(participant/trial_type),
data = data)
# rule
fit_1b <- aov(D_score ~ rule + Error(participant/trial_type),
data = data)
# block_order
fit_1c <- aov(D_score ~ block_order + Error(participant/trial_type),
data = data)
AICc(fit_0$`participant:trial_type`,
fit_1a$`participant:trial_type`,
fit_1b$`participant:trial_type`,
fit_1c$`participant:trial_type`)
# tt * rule
fit_2a <- aov(D_score ~ trial_type*rule + Error(participant/trial_type),
data = data)
# tt * block order
fit_2b <- aov(D_score ~ trial_type*block_order + Error(participant/trial_type),
data = data)
AICc(fit_1a$`participant:trial_type`,
fit_2a$`participant:trial_type`,
fit_2b$`participant:trial_type`)
# http://www.cookbook-r.com/Statistical_analysis/ANOVA/
# forward selection
# variable 1
# null model
fit_0 <- aov(D_score ~ Error(participant/trial_type),
data = data)
# tt
fit_tt <- aov(D_score ~ trial_type + Error(participant/trial_type),
data = data)
# rule
fit_rule <- aov(D_score ~ rule + Error(participant/trial_type),
data = data)
# block_order
fit_bo <- aov(D_score ~ block_order + Error(participant/trial_type),
data = data)
AICc(fit_0$`participant:trial_type`,
fit_tt$`participant:trial_type`,
fit_rule$`participant:trial_type`,
fit_bo$`participant:trial_type`)
# tt * rule
fit_tt_rule <- aov(D_score ~ trial_type*rule + Error(participant/trial_type),
data = data)
# tt * block order
fit_tt_bo <- aov(D_score ~ trial_type*block_order + Error(participant/trial_type),
data = data)
AICc(fit_tt$`participant:trial_type`,
fit_tt_rule$`participant:trial_type`,
fit_tt_bo$`participant:trial_type`)
summary(fit_tt)
fit_full <- aov(D_score ~ trial_type * block_order * rule + Error(participant/trial_type),
data = data)
car::Anova(fit_full$participant)
car::Anova(fit_full$`participant:trial_type`)
fit_full <- aov(D_score ~ trial_type * block_order * rule + Error(participant/trial_type),
data = data)
car::Anova(fit_full$participant)
car::Anova(fit_full$`participant:trial_type`)
# below is an alt method using ez. it's interactions match above, but its main effects do not, and are not simply due to SS type errors. The below matches JASP, suggesting that the above aov() method does not do something correctly
library(ez)
library(schoRsch)
fit_selected_2 <-
ez::ezANOVA(data = data,
dv = D_score,
within = trial_type,
between = c(block_order, rule),
wid = participant,
type = 3,
detailed = TRUE) %>%
schoRsch::anova_out(print = FALSE)
fit_selected_2$`--- FORMATTED RESULTS ------------------------------------`
# below is an alt method using ez. it's interactions match above, but its main effects do not, and are not simply due to SS type errors. The below matches JASP, suggesting that the above aov() method does not do something correctly
fit_selected_2 <-
ez::ezANOVA(data = data,
dv = D_score,
within = trial_type,
between = c(block_order, rule),
wid = participant,
type = 3,
detailed = TRUE) %>%
schoRsch::anova_out(print = FALSE)
fit_selected_2$`--- FORMATTED RESULTS ------------------------------------`
# http://www.cookbook-r.com/Statistical_analysis/ANOVA/
# forward selection
# variable 1
# null model
fit_0 <- aov(D_score ~ Error(participant/trial_type),
data = data)
# tt
fit_tt <- aov(D_score ~ trial_type + Error(participant/trial_type),
data = data)
# rule
fit_rule <- aov(D_score ~ rule + Error(participant/trial_type),
data = data)
# block_order
fit_bo <- aov(D_score ~ block_order + Error(participant/trial_type),
data = data)
AICc(fit_0$`participant:trial_type`,
fit_tt$`participant:trial_type`,
fit_rule$`participant:trial_type`,
fit_bo$`participant:trial_type`)
# tt * rule
fit_tt_rule <- aov(D_score ~ trial_type*rule + Error(participant/trial_type),
data = data)
# tt * block order
fit_tt_bo <- aov(D_score ~ trial_type*block_order + Error(participant/trial_type),
data = data)
AICc(fit_tt$`participant:trial_type`,
fit_tt_rule$`participant:trial_type`,
fit_tt_bo$`participant:trial_type`)
AIC(fit_full)
AIC(fit_full$`participant:trial_type`)
AIC(fit_full$participant)
AICc(fit_tt$participant,
fit_tt_rule$participant,
fit_tt_bo$participant)
summary(fit_tt)
fit_full <- aov(D_score ~ trial_type * block_order * rule + Error(participant/trial_type),
data = data)
AIC(fit_full$participant)
AIC(fit_full$`participant:trial_type`)
car::Anova(fit_full$participant)
car::Anova(fit_full$`participant:trial_type`)
# tt * rule
fit_tt_rule <- aov(D_score ~ trial_type*rule + Error(participant/trial_type),
data = data)
# tt * block order
fit_tt_bo <- aov(D_score ~ trial_type*block_order + Error(participant/trial_type),
data = data)
# how to distinguish between these? which should be used?
AICc(fit_tt$`participant:trial_type`,
fit_tt_rule$`participant:trial_type`,
fit_tt_bo$`participant:trial_type`)
AICc(fit_tt$participant,
fit_tt_rule$participant,
fit_tt_bo$participant)
fit_full <- aov(D_score ~ trial_type * block_order * rule + Error(participant/trial_type),
data = data)
AIC(fit_full$participant)
AIC(fit_full$`participant:trial_type`)
### doing it backward would probably provide the opposite conclusion, that the full model is best
car::Anova(fit_full$participant)
car::Anova(fit_full$`participant:trial_type`)
car::Anova(fit_full$`participant:trial_type`, type = 3)
car::Anova(fit_full$participant, type = 3)
car::Anova(fit_full$participant, type = 2)  # 3 throws an error?
car::Anova(fit_full$`participant:trial_type`, type = 3)
fit_full <- aov(D_score ~ trial_type * block_order * rule + Error(participant/trial_type),
data = data)
AIC(fit_full$participant)
AIC(fit_full$`participant:trial_type`)
### doing it backward would probably provide the opposite conclusion, that the full model is best
car::Anova(fit_full$participant, type = 2)  # 3 throws an error?
car::Anova(fit_full$`participant:trial_type`, type = 3)
summary(fit_tt)
Anova(fit_tt, type = 3)
Anova(fit_tt$`participant:trial_type`, type = 3)
summary(fit_tt)
Anova(fit_tt$`participant:trial_type`, type = 3)
Anova(fit_tt$`(Intercept)`, type = 3)
Anova(fit_tt$participant, type = 3)
summary(fit_tt)
Anova(fit_tt$`participant:trial_type`, type = 3)
Anova(fit_tt$`participant:trial_type`, type = 2)
Anova(fit_tt$`participant:trial_type`, type = 3)
summary(fit_full)
?summary
?summary.aov
summary(fit_full)
fit_full <- lm(D_score ~ trial_type * block_order * rule + Error(participant/trial_type),
data = data)
fit_full <- aov(D_score ~ trial_type * block_order * rule + Error(participant/trial_type),
data = data)
fit_full <- aov(D_score ~ trial_type * block_order * rule + Error(participant/trial_type),
contrasts = list(trial_type = "contr.sum",
block_order = "contr.sum",
rule = "contr.sum"),
data = data)
summary(fit_full)
fit_full <- aov(D_score ~ trial_type * block_order * rule + Error(participant/trial_type),
data = data)
summary(fit_full)
fit_full <- aov(D_score ~ trial_type * block_order * rule + Error(participant/trial_type),
contrasts = list(trial_type = "contr.sum",
block_order = "contr.sum",
rule = "contr.sum"),
data = data)
summary(fit_full)
?aov
# working but model not specificied correctly
fit_null <- aov(D_score ~ 1,
data = data)
fit_full <- aov(D_score ~ rule*trial_type*block_order,
contrasts = list(trial_type = "contr.sum",
rule = "contr.sum",
block_order = "contr.sum"),
data = data)
step(fit_null,
scope = list(lower = fit_null, upper = fit_full),
direction = "forward",
k = 2)
# http://www.cookbook-r.com/Statistical_analysis/ANOVA/
# forward selection
# variable 1
# null model
fit_0 <- aov(D_score ~ Error(participant/trial_type),
data = data)
# tt
fit_tt <- aov(D_score ~ trial_type + Error(participant/trial_type),
data = data)
# rule
fit_rule <- aov(D_score ~ rule + Error(participant/trial_type),
data = data)
# block_order
fit_bo <- aov(D_score ~ block_order + Error(participant/trial_type),
data = data)
AICc(fit_0$`participant:trial_type`,
fit_tt$`participant:trial_type`,
fit_rule$`participant:trial_type`,
fit_bo$`participant:trial_type`)
# tt * rule
fit_tt_rule <- aov(D_score ~ trial_type*rule + Error(participant/trial_type),
data = data)
# tt * block order
fit_tt_bo <- aov(D_score ~ trial_type*block_order + Error(participant/trial_type),
data = data)
# how to distinguish between these? which should be used?
AICc(fit_tt$`participant:trial_type`,
fit_tt_rule$`participant:trial_type`,
fit_tt_bo$`participant:trial_type`)
AICc(fit_tt$participant,
fit_tt_rule$participant,
fit_tt_bo$participant)
summary(fit_tt)
# below is an alt method using ez. it's interactions match above, but its main effects do not, and are not simply due to SS type errors. The below matches JASP, suggesting that the above aov() method does not do something correctly
fit_selected_2 <-
ez::ezANOVA(data = data,
dv = D_score,
within = trial_type,
between = c(block_order, rule),
wid = participant,
type = 3,
detailed = TRUE) %>%
schoRsch::anova_out(print = FALSE)
fit_selected_2$`--- FORMATTED RESULTS ------------------------------------`
fit_selected_2 <-
ez::ezANOVA(data = data,
dv = D_score,
within = trial_type,
between = c(block_order, rule),
wid = participant,
type = 2,
detailed = TRUE) %>%
schoRsch::anova_out(print = FALSE)
fit_selected_2$`--- FORMATTED RESULTS ------------------------------------`
fit_selected_2 <-
ez::ezANOVA(data = data,
dv = D_score,
within = trial_type,
between = c(block_order, rule),
wid = participant,
type = 3,
detailed = TRUE) %>%
schoRsch::anova_out(print = FALSE)
fit_selected_2$`--- FORMATTED RESULTS ------------------------------------`
?kable
library(knittr)
library(knitr)
AICc(fit_0$`participant:trial_type`,
fit_tt$`participant:trial_type`,
fit_rule$`participant:trial_type`,
fit_bo$`participant:trial_type`) %>%
kable()
summary(fit_tt) %>%
kable()
summary(fit_tt)
x <- summary(fit_tt)
x$`Error: participant:trial_type` %>%
kable()
y = x$`Error: participant:trial_type`
y %>%
kable()
y[1]
y[2]
y[1]
summary(fit_tt)
fit_selected_2$`--- FORMATTED RESULTS ------------------------------------` %>%
kable()
library(tidyverse)
library(car)
library(MuMIn)  # for AICc (AIC corrected for small samples)
library(ez)
library(schoRsch)
library(knitr)
data <-
read.csv(file = "data/processed/processed data.csv") %>%
filter(whole_task_excluded == 0) %>%  # removed participants who were excluded
rename(tt1 = D_tt1_screened,
tt2 = D_tt2_screened,
tt3 = D_tt3_screened,
tt4 = D_tt4_screened) %>%
gather(trial_type, D_score, c(tt1, tt2, tt3, tt4)) %>%
mutate(participant = as.factor(participant),
trial_type = as.factor(trial_type))
step(fit_null,
scope = list(lower = fit_null, upper = fit_full),
direction = "forward",
k = 2) %>% kable()
?broom
library(broom)
tiday(fit_tt)
tidy(fit_tt)
tidy(fit_tt$`participant:trial_type`)
tidy(fit_tt$`participant:trial_type`) %>%
kable()
tidy(fit_tt$`participant:trial_type`)
tidy(fit_tt$`participant:trial_type`) %>%
round(3) %>%
kable()
tidy(fit_tt$`participant:trial_type`)
tidy(fit_tt$`participant:trial_type`) %>%
kable()
tidy(fit_full) %>%
kable()
round_df <- function(df, digits) {
nums <- vapply(df, is.numeric, FUN.VALUE = logical(1))
df[,nums] <- round(df[,nums], digits = digits)
(df)
}
tidy(fit_full) %>%
round_df(3) %>%
kable()
tidy(fit_tt$`participant:trial_type`) %>%
round_df(3) %>%
kable()
fit_full <- aov(D_score ~ trial_type * block_order * rule + Error(participant/trial_type),
contrasts = list(trial_type = "contr.sum",
block_order = "contr.sum",
rule = "contr.sum"),
data = data)
AIC(fit_full$participant,
fit_full$`participant:trial_type`) %>%
kable()
### doing it backward would probably provide the opposite conclusion, that the full model is best
tidy(fit_full) %>%
round_df(3) %>%
kable()
fit_full <- aov(D_score ~ trial_type * block_order * rule + Error(participant/trial_type),
contrasts = list(trial_type = "contr.sum",
block_order = "contr.sum",
rule = "contr.sum"),
data = data)
AIC(fit_full$participant,
fit_full$`participant:trial_type`) %>%
kable()
### doing it backward would probably provide the opposite conclusion, that the full model is best
tidy(fit_full) %>%
round_df(3) %>%
kable()
tidy(fit_tt) %>%
round_df(3) %>%
kable()
tidy(fit_tt$`participant:trial_type`) %>%
round_df(3) %>%
kable()
# below is an alt method using ez. it's interactions match above, but its main effects do not, and are not simply due to SS type errors. The below matches JASP, suggesting that the above aov() method does not do something correctly
# the below results do not match statview results afaik.
fit_selected_2 <-
ez::ezANOVA(data = data,
dv = D_score,
within = trial_type,
between = c(block_order, rule),
wid = participant,
type = 3,
detailed = TRUE) %>%
schoRsch::anova_out(print = FALSE)
fit_selected_2$`--- FORMATTED RESULTS ------------------------------------` %>%
kable()
